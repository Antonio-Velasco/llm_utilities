{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To locate FIT and LOT in large documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "import json\n",
    "import tiktoken\n",
    "import openai\n",
    "import os\n",
    "\n",
    "with open('../settings.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Set form recogniser client\n",
    "credential = AzureKeyCredential(data[\"FORM_KEY\"])\n",
    "document_analysis_client = DocumentAnalysisClient(data[\"FORM_ENDPOINT\"], credential)\n",
    "\n",
    "# This example also requires an OpenAI API key\n",
    "os.environ['OPENAI_API_KEY'] = data['OPENAI_API_KEY']\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# Set up Token Enconder for meassurement\n",
    "encoder = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n",
      "8\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "\n",
    "path = \"../data/206_12a-3 (SW Clair F1) Geological EOWR_Signed.pdf\"\n",
    "\n",
    "relevant_text = \"\"\n",
    "with pdfplumber.open(path) as pdf:\n",
    "    for page in pdf.pages:\n",
    "        if page.search(\"FIT\") or page.search(\"LOT\"):\n",
    "            relevant_text += pdf.pages[page.page_number].extract_text()\n",
    "            print(page.page_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8018"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoder.encode(relevant_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While considerably less content, it is still prone to go over the model's token limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = relevant_text\n",
    "\n",
    "json_template = json.dumps({ \n",
    "    \"Test Type\": \"<FIT or LOT>\",\n",
    "    \"Casing Shoe\": \"<Casing shoe size>\",\n",
    "    \"TVD (m)\": \"TVD in meters\",\n",
    "    \"Surface pressure (psi)\": \"<MW value in sg>\",\n",
    "    \"MW (sg)\": \"<MW value in sg>\",\n",
    "    \"EMW (sg)\": \"<EMW value in sg. Calculated as: EMW = MW + (P-FIT / (TVD-shoe * 1.421))>\"\n",
    "})\n",
    "\n",
    "system = f\"\"\"\n",
    "You are an API that given a text extracted using OCR from an End of Well Report will extract Formation Integrity Test (FIT) and Leak Off Test (LOT) results.\n",
    "Your response will be a JSON with as many entries as needed in the format {json_template}\n",
    "If there is a field that you can not find, set it a null.\n",
    "If the document has any kind of errors or is corrupted, add a field {{\"errors\": \"<error description>\"}}\n",
    "If there is any additional information of feedback from the infromation extraction, add a {{\"notes\": \"<additional-information>\"}}\n",
    "\n",
    "The format of your input will be the text of the relevant page.\n",
    "\"\"\"\n",
    "\n",
    "config = {\n",
    "    \"temperature\": 0.2,\n",
    "    \"max_tokens\": 512,\n",
    "    \"top_p\": 1,\n",
    "}\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": system},\n",
    "      {\"role\": \"user\", \"content\": input},\n",
    "    ],\n",
    "    temperature=config[\"temperature\"],\n",
    "    max_tokens=config[\"max_tokens\"],\n",
    "    top_p=config[\"top_p\"],\n",
    "  )\n",
    "\n",
    "print(response.get(\"choices\")[0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"text\": \"Formation Integrity Test (FIT)\\n\\nCasing Shoe: 10000 ft\\nTVD (m): 3000\\nSurface pressure (psi): 5000\\nMW (sg): 1.2\\n\\nLeak Off Test (LOT)\\n\\nCasing Shoe: 10000 ft\\nTVD (m): 3000\\nSurface pressure (psi): 5000\\nMW (sg): 1.2\\nEMW (sg): 1.3\"}\n"
     ]
    }
   ],
   "source": [
    "input = relevant_text\n",
    "\n",
    "json_template = json.dumps({ \n",
    "    \"Test Type\": \"<FIT or LOT>\",\n",
    "    \"Casing Shoe\": \"<Casing shoe size>\",\n",
    "    \"TVD (m)\": \"TVD in meters\",\n",
    "    \"Surface pressure (psi)\": \"<MW value in sg>\",\n",
    "    \"MW (sg)\": \"<MW value in sg>\",\n",
    "    \"EMW (sg)\": \"<EMW value in sg. Calculated as: EMW = MW + (P-FIT / (TVD-shoe * 1.421))>\"\n",
    "})\n",
    "\n",
    "system = f\"\"\"\n",
    "You are an API that given a text extracted using OCR from an End of Well Report will extract Formation Integrity Test (FIT) and Leak Off Test (LOT) results.\n",
    "Your response will be a JSON with as many entries as needed in the format {json_template}\n",
    "If there is a field that you can not find, set it a null.\n",
    "If the document has any kind of errors or is corrupted, add a field {{\"errors\": \"<error description>\"}}\n",
    "If there is any additional information of feedback from the infromation extraction, add a {{\"notes\": \"<additional-information>\"}}\n",
    "\n",
    "The format of your input will be the text of the relevant page.\n",
    "\"\"\"\n",
    "\n",
    "config = {\n",
    "    \"temperature\": 0.2,\n",
    "    \"max_tokens\": 512,\n",
    "    \"top_p\": 1,\n",
    "}\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-16k\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": system},\n",
    "      {\"role\": \"user\", \"content\": input},\n",
    "    ],\n",
    "    temperature=config[\"temperature\"],\n",
    "    max_tokens=config[\"max_tokens\"],\n",
    "    top_p=config[\"top_p\"],\n",
    "  )\n",
    "\n",
    "print(response.get(\"choices\")[0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good enough with 16k, let's check with form recogniser and see "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(encoder.encode(extracted_text[\"content\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = extracted_text[\"content\"]\n",
    "\n",
    "json_template = json.dumps({ \n",
    "    \"Test Type\": \"<FIT or LOT>\",\n",
    "    \"Casing Shoe\": \"<Casing shoe size>\",\n",
    "    \"TVD (m)\": \"TVD in meters\",\n",
    "    \"Surface pressure (psi)\": \"<MW value in sg>\",\n",
    "    \"EMW (sg)\": \"<EMW value in sg>\"\n",
    "})\n",
    "\n",
    "system = f\"\"\"\n",
    "You are an API that given a text extracted using OCR from an End of Well Report will extract Formation Integrity Test (FIT) and Leak Off Test (LOT) results.\n",
    "There can be multiple tests per shoe size and depth, please report them all.\n",
    "Your response will be a JSON with one entry per test in the format {json_template}.\n",
    "If there is a field that you can not find, set it a null.\n",
    "If the document has any kind of errors or is corrupted, add a field {{\"errors\": \"<error description>\"}}\n",
    "If there is any additional information of feedback from the infromation extraction, add a {{\"notes\": \"<additional-information>\"}}\n",
    "\n",
    "The format of your input will be the text of the relevant page.\n",
    "\"\"\"\n",
    "\n",
    "config = {\n",
    "    \"temperature\": 0.2,\n",
    "    \"max_tokens\": 512,\n",
    "    \"top_p\": 1,\n",
    "}\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-16k\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": system},\n",
    "      {\"role\": \"user\", \"content\": input},\n",
    "    ],\n",
    "    temperature=config[\"temperature\"],\n",
    "    max_tokens=config[\"max_tokens\"],\n",
    "    top_p=config[\"top_p\"],\n",
    "  )\n",
    "\n",
    "print(response.get(\"choices\")[0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Llama Index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"../llama_dir/\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The EMW of the FIT performed on the well 206/12a-3 is 1.75sg.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"what's the EMW of the FIT performed on the well 206/12a-3?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two tests were performed on the well 206/12a-3.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"How many test where performend on the well 206/12a-3?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LOT and FIT are reported on page 53 of the end of well 206/12a-3 report.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"In which page on the end of well 206/12a-3 report are the LOT and FIT reported?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLama Index Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[path]\n",
    ").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"In which page are the LOT and FIT reported?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_template = json.dumps({\n",
    "    \"Test Type\": \"<FIT or LOT>\",\n",
    "    \"Casing Shoe\": \"<Casing shoe size>\",\n",
    "    \"TVD (m)\": \"TVD in meters\",\n",
    "    \"Surface pressure (psi)\": \"<Surface pressure value>\",\n",
    "    \"MW (sg)\": \"<MW value in sg>\",\n",
    "    \"EMW (sg)\": \"<EMW value in sg>\"\n",
    "})\n",
    "\n",
    "system = f\"\"\"\n",
    "You are an assistant that given a text extracted using OCR from an End of Well Report will extract 'Formation Integrity Test' (FIT) and 'Leak Off Test' (LOT) results.\n",
    "There can be multiple tests, report all of them.\n",
    "Write your output as a list with an entry with the format {json_template} per each test you find, separated by commas.\n",
    "If there is a field that you can not find, set it a null.\n",
    "If the document has any kind of errors or is corrupted, add a field {{\"errors\": \"<error description>\"}}\n",
    "If there is any additional information of feedback from the infromation extraction, add a {{\"notes\": \"<additional-information>\"}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Test Type\": \"FIT\", \"Casing Shoe\": \"20\", \"TVD (m)\": \"536\", \"Surface pressure (psi)\": \"101.0\", \"MW (sg)\": \"1.15\", \"EMW (sg)\": \"1.26\"},\n",
      "{\"Test Type\": \"LOT\", \"Casing Shoe\": \"20\", \"TVD (m)\": \"536\", \"Surface pressure (psi)\": \"84.0\", \"MW (sg)\": \"1.15\", \"EMW (sg)\": \"1.26\"},\n",
      "{\"Test Type\": \"FIT\", \"Casing Shoe\": \"13 3/8\", \"TVD (m)\": null, \"Surface pressure (psi)\": \"328\", \"MW (sg)\": \"1.55\", \"EMW (sg)\": null},\n",
      "{\"Test Type\": \"LOT\", \"Casing Shoe\": \"13 3/8\", \"TVD (m)\": null, \"Surface pressure (psi)\": \"360\", \"MW (sg)\": \"1.55\", \"EMW (sg)\": null}\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(system)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data from Form Recogniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "# OCR from base form recogniser\n",
    "def base_form_recogniser(pdf_bytes: io.BytesIO) -> dict:\n",
    "    document = pdf_bytes.getvalue()\n",
    "\n",
    "    # Start the document analysis\n",
    "    poller = document_analysis_client.begin_analyze_document(\"prebuilt-document\", document, polling_interval=5)\n",
    "\n",
    "    # Get the result\n",
    "    result = poller.result()\n",
    "    data = result.to_dict()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n",
      "8\n",
      "13\n",
      "15\n",
      "52\n",
      "53\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "from PyPDF4 import PdfFileWriter, PdfFileReader\n",
    "\n",
    "inputpdf = PdfFileReader(open(path, \"rb\"))\n",
    "\n",
    "output = PdfFileWriter()\n",
    "\n",
    "relevant_text = \"\"\n",
    "\n",
    "with pdfplumber.open(path) as pdf:\n",
    "    for page in pdf.pages:\n",
    "        if page.search(\"FIT\") and page.search(\"LOT\"):\n",
    "            output.addPage(inputpdf.pages[page.page_number])\n",
    "            print(page.page_number)\n",
    "\n",
    "output_bytesio = io.BytesIO()\n",
    "\n",
    "output.write(output_bytesio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text = base_form_recogniser(output_bytesio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader, VectorStoreIndex, ServiceContext\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index import Document\n",
    "\n",
    "text_list = [extracted_text[\"content\"]]\n",
    "documents = [Document(text=t) for t in text_list]\n",
    "\n",
    "node_parser = SimpleNodeParser.from_defaults(chunk_size=4096, chunk_overlap=200)\n",
    "service_context = ServiceContext.from_defaults(node_parser=node_parser)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_template = json.dumps({\n",
    "    \"Test Type\": \"<FIT or LOT>\",\n",
    "    \"Casing Shoe\": \"<Casing shoe size>\",\n",
    "    \"TVD (m)\": \"TVD in meters\",\n",
    "    \"Surface pressure (psi)\": \"<Surface pressure value>\",\n",
    "    \"MW (sg)\": \"<MW value in sg>\",\n",
    "    \"EMW (sg)\": \"<EMW value in sg>\"\n",
    "})\n",
    "\n",
    "system = f\"\"\"\n",
    "You are an assistant that given a text extracted using OCR from an End of Well Report will extract 'Formation Integrity Test' (FIT) and 'Leak Off Test' (LOT) results.\n",
    "You must prioritize reporting the EMW value, meassured in sg.\n",
    "There can be multiple tests, report all of them.\n",
    "Write an entry with the format {json_template} per each test you find.\n",
    "If there is a field that you can not find, set it a null.\n",
    "If the document has any kind of errors or is corrupted, add a field {{\"errors\": \"<error description>\"}}\n",
    "If there is any additional information of feedback from the infromation extraction, add a {{\"notes\": \"<additional-information>\"}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Test Type\": \"FIT\", \"Casing Shoe\": \"9 5/8\", \"TVD (m)\": \"2081.4\", \"Surface pressure (psi)\": \"null\", \"MW (sg)\": \"null\", \"EMW (sg)\": \"1.69\"}\n",
      "{\"Test Type\": \"LOT\", \"Casing Shoe\": \"null\", \"TVD (m)\": \"536\", \"Surface pressure (psi)\": \"84.0\", \"MW (sg)\": \"null\", \"EMW (sg)\": \"1.26\"}\n",
      "{\"Test Type\": \"LOT\", \"Casing Shoe\": \"null\", \"TVD (m)\": \"null\", \"Surface pressure (psi)\": \"null\", \"MW (sg)\": \"null\", \"EMW (sg)\": \"null\"}\n",
      "{\"Test Type\": \"FIT\", \"Casing Shoe\": \"13 3/8\", \"TVD (m)\": \"null\", \"Surface pressure (psi)\": \"null\", \"MW (sg)\": \"null\", \"EMW (sg)\": \"1.55\"}\n",
      "{\"Test Type\": \"FIT\", \"Casing Shoe\": \"null\", \"TVD (m)\": \"null\", \"Surface pressure (psi)\": \"null\", \"MW (sg)\": \"null\", \"EMW (sg)\": \"null\"}\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(system)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
