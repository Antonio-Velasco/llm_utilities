{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To locate FIT and LOT in large documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "import json\n",
    "import openai\n",
    "import os\n",
    "\n",
    "with open('../local_settings.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Set form recogniser client\n",
    "credential = AzureKeyCredential(data[\"FORM_KEY\"])\n",
    "document_analysis_client = DocumentAnalysisClient(data[\"FORM_ENDPOINT\"], credential)\n",
    "\n",
    "# This example also requires an OpenAI API key\n",
    "os.environ['OPENAI_API_KEY'] = data['OPENAI_API_KEY']\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_names = [\"Mission\", \"Colour Palette\"]\n",
    "field_descriptions = [\"\", \"\"]\n",
    "\n",
    "json_template = json.dumps({\"Results\": [dict(zip(field_names, field_descriptions))]})\n",
    "\n",
    "\n",
    "system = f\"\"\"\n",
    "You are an assistant that given a text extracted using OCR from a document will extract user provided data fields.\n",
    "Fields can have multiple formats.\n",
    "Write your output as a JSON with an entry with the format {json_template} per each test you find.\n",
    "If there is a field that you can not find, set it a null.\n",
    "If there is any additional information of feedback from the infromation extraction, add a {{\"notes\": \"<additional-information>\"}}\n",
    "\"\"\"   # noqa E501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "path = \"../data/example/Elastacloud-Brand-Book.pdf\"\n",
    "\n",
    "relevant_text = \"\"\n",
    "with pdfplumber.open(path) as pdf:\n",
    "    for page in pdf.pages:\n",
    "        relevant_text += pdf.pages[page.page_number-1].extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, ServiceContext\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index import Document\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from llama_index import LLMPredictor\n",
    "\n",
    "\n",
    "documents = [Document(text=relevant_text)]\n",
    "\n",
    "node_parser = SimpleNodeParser.from_defaults(chunk_size=4096,\n",
    "                                                chunk_overlap=200)\n",
    "                                                \n",
    "llm = ChatOpenAI(temperature=0, max_tokens=512)\n",
    "llm_predictor = LLMPredictor(llm=llm)\n",
    "service_context = ServiceContext.from_defaults(node_parser=node_parser,\n",
    "                                                llm_predictor=llm_predictor)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(documents,\n",
    "                                        service_context=service_context)\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"What is EC color palette?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d696ffca-125f-4ab1-bad9-f1d7f82c0572': {},\n",
       " 'e2aeb521-8bc5-496c-9624-0a928c435b5e': {}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function list.index(value, start=0, stop=9223372036854775807, /)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.source_nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF retrieval tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content:\n",
      " A culture of giving back\n",
      "Elastacloud firmly believes that data can break boundaries \n",
      "and benefit humanity, which is why we are heavily \n",
      "invested in projects and actions that improve outcomes \n",
      "for individuals and the planet. One way we do this is by \n",
      "empowering our Elastaclouders to contribute to the wider \n",
      "community through sharing their digital skills.For well over a decade, Elastacloud has established and \n",
      "maintained various industry user groups: joining together \n",
      "more than 12,000 people around the world for community-\n",
      "based learning and innovation. This includes one of the \n",
      "largest data science communities in Europe.\n",
      "We are also proud to sponsor computer labs at Shanti \n",
      "Bhavan, a residential school in India for children born into \n",
      "the lowest socioeconomic class, which aims to uplift from \n",
      "poverty through education and opportunity. Our team in \n",
      "India run coding labs for the students there, sometimes \n",
      "held in the Elastacloud offices. \n",
      "Elastacloud has a deeply embedded commitment to \n",
      "inclusivity, support, collaboration, nurturing and valuing \n",
      "its people. Across the world, we actively encourage \n",
      "Elastaclouders to find a healthy balance of work and \n",
      "personal life: promoting time for self, family and friends, \n",
      "for leisure and wellbeing. In India for example, we  \n",
      "don’t allow our teams to consistently work outside of \n",
      "standard operating hours, despite this generally being  \n",
      "the expectation that people experience within Indian \n",
      "corporate culture.\n",
      "We take on graduates and experienced individuals from \n",
      "all over (including from Shanti Bhavan) who possess the \n",
      "passion and mindset to make a difference. ‘Elastaclouders’ \n",
      "are encouraged to invest at least an hour of their own time \n",
      "each month to mentor and support children, teaching them \n",
      "how to code and advance their IT literacy. This instils our \n",
      "graduates with a sense of community: ensuring that our \n",
      "values are passed on to more people and helping to embed \n",
      "sustainable social equity within the technologies we work in. \n",
      "Since 2020, Elastacloud has been a foundation sponsor of \n",
      "The National Museum of Computing, which is based on the \n",
      "famous Bletchley Park estate where the Enigma code was \n",
      "cracked, turning the tide of the war. We’re active in a wide \n",
      "variety of events and activities at this inspiring educational \n",
      "venue; one that carries so much historical value and \n",
      "significance to our industry. \n",
      "Although our Elastaclouders are widely spread \n",
      "geographically, we are united by a culture of pioneering for \n",
      "the greater good: harnessing data to break boundaries and \n",
      "benefit our people and our world. \n",
      " metadata:\n",
      " {'source': '../data/example/Elastacloud-Brand-Book.pdf', 'page': 5}\n"
     ]
    }
   ],
   "source": [
    "# read a pdf and answers question on it\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"../data/example/Elastacloud-Brand-Book.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "# check the metadata\n",
    "pg_no=6\n",
    "print(f\"Content:\\n {pages[pg_no].page_content} \\n metadata:\\n {pages[pg_no].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.document_loaders.pdf.PyPDFLoader at 0x23f22935710>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='BRAND BOOK V4\\nMarch 2023', metadata={'source': '../data/example/Elastacloud-Brand-Book.pdf', 'page': 0}),\n",
       " Document(page_content='WHO WE ARE\\nOUR VISION\\nGlobal industry transformation through data and next generation AI\\nWe believe every business has immense power in its data. The power to unlock growth, to unleash intelligence, and to accelerate \\noutcomes – responsibly, and with the help of AI.\\nWe’re playing in a new game –where data is the fuel for your future growth, and AI is the accelerator to your destination.\\nIn this new era of AI, the power of data and AI is no longer limited to the few companies with skilled data scientists and experts. \\nNow, every business has opportunities to do things better, smarter, faster – to become more intelligent.\\nElastacloud will lead this new era and help democratise intelligence – empowering businesses to grow sustainably –  \\nby unleashing the power of their data with intelligent solutions and services.\\nOUR MISSION\\nTo pioneer through data for the greater good \\n– utilising cutting-edge data science and intelligence to create a better, more connected, and sustainable world.\\xa0\\nOUR VALUES\\nPioneering through data and next generation AI\\nTrust and transparency\\nAccountability\\nCommunity and sustainability\\nDiversity and inclusion', metadata={'source': '../data/example/Elastacloud-Brand-Book.pdf', 'page': 1}),\n",
       " Document(page_content='WHO WE ARE\\nOUR BRAND POSITIONING\\nElastacloud are data pioneers and industry-leading innovators  \\nwho challenge the limits of possibility to accelerate transformation and deliver  \\ngame-changing insights and outcomes to some of the world’s leading brands.  \\nWith a culture of pioneering for the greater good, and utilising cutting-edge data  \\nscience and intelligence, we unleash the power and opportunity hidden within data \\nthrough the design and implementation of world-class, enterprise-grade solutions.\\nOUR BRAND PROPOSITION\\nUtilising pioneering techniques, data science, intelligence,  \\nand innovation, we will unleash the power and opportunity  \\nhidden within your data to accelerate transformation and deliver \\ngame-changing insights and outcomes to your business, fast. \\nOUR BRAND STRAPLINE\\nPioneering Through Data\\nOUR ELEVATOR PITCH\\nWe can unleash the hidden power within your data to  \\nelevate your business, accelerate outcomes and deliver  \\ngame-changing insights, fast.', metadata={'source': '../data/example/Elastacloud-Brand-Book.pdf', 'page': 2}),\n",
       " Document(page_content='OUR FIVE CORE MESSAGES\\n1. We are data pioneers\\nThrough the design and implementation of world-class, enterprise-grade solutions, Elastacloud are \\npioneers in the way data is gathered, structured and harnessed. Our revolutionary approach and steely \\ndetermination to innovate, consistently delivers game-changing insights, outcomes and transformation.\\n2. We unleash the power of data\\nWhen it comes to data, we are masters in the art of the possible. Whatever the business objectives –  \\nfrom sustainability and growth to transformation – our teams of technologists have the vision, knowledge, \\nand expertise to unleash the power and opportunity hidden within any data.\\n3. We accelerate transformational outcomes\\nElastacloud are accelerators, empowering businesses to get where they’re going faster, securely and  \\ncost-effectively. Because we design and implement bespoke intelligence-led data solutions within weeks, \\nnot months or years, we deliver accelerated outcomes and transformation faster than anyone else.\\n4. We are trusted advisors\\nElastacloud serve as strategic partners to global brand leaders; employing some of the finest talent in  \\nthe world to advise, innovate and embed cutting-edge, ground-breaking data science and intelligence.\\n5. We are a global community\\nAlthough our people are spread across the world, we are united by a culture of pioneering for the greater \\ngood. We love to solve big problems and give people the freedom to experiment, learn quickly, and share \\nideas with others. We are not afraid of the unconventional and encourage our teams to take on big \\nchallenges that could fail, so we can learn and continue striving for breakthrough outcomes.', metadata={'source': '../data/example/Elastacloud-Brand-Book.pdf', 'page': 3}),\n",
       " Document(page_content='OUR BRAND TONE OF VOICE / PERSONALITY\\n   Overall, Elastacloud speaks with a voice that is confident, clear, \\ndirect and concise: always cutting through noise and conveying a clever \\nand playful personality that builds rapport with each specific audience. \\nLanguage should be tailored to reflect and be appropriate to whomever  \\nis being communicated to, for example the business decision maker \\nversus the tech decision maker.\\n   We are trustworthy and dependable, and that can be validated by \\nsome of the accolades we have received and brand names we have as \\nclients. But we need to give people reason to trust and believe what we \\nsay by demonstrating our knowledge and leader role in the industry.\\n   We are successful, knowledgeable, expert, respected by our industry \\npeers, accomplished and self-assured… but we must never sound \\n‘cocksure’ or arrogant.\\n   We call ourselves pioneers because we are brave, bold, adventurous, \\ncurious and always willing to challenge. We see ourselves as disruptors, \\neven maverick at times, and some might describe us as anti-\\nestablishment. We don’t just accept things as they are if we believe  \\nthere is a better way to do things, but we are never belligerent or \\naggressive. Determined with self-belief yes, rail-roading never.   We are collaborators and partners. This means we are flexible, \\nco-operative, open-minded and non-judgemental. We are extremely \\n‘human’: friendly, approachable and accessible, not a faceless digital \\nbehemoth. We are proud of our playful, creative, sometimes quirky \\nculture and personality.\\n   We are ‘woke’, passionate and caring. We genuinely believe that  \\ndata can be used to build a better world and to improve outcomes  \\non a local and global scale. We want to be a force for good and we \\nlead by example. We care deeply about the welfare of our planet and \\nhumanity, firmly believing that we have an important role to play.\\n   The language we use shouldn’t be overly jargon-heavy although \\nthe audience will generally be knowledgeable in the fields of data \\nand technology so needs to be respectful and mindful of that (not \\ncondescending or too dumbed down). Text needs to talk the language  \\nof CIOs and data professionals, but also give them the language to  \\nspeak to their CEO, CFO, Sustainability Officer or ESG Committee.  \\nIt must strike a balance between clarity and over-simplification.\\n   We always speak in the plural (we, us, ‘what we do’, ‘who we are’).  \\nWe can however refer to ourselves as Elastacloud and Elastaclouders.', metadata={'source': '../data/example/Elastacloud-Brand-Book.pdf', 'page': 4}),\n",
       " Document(page_content='OUR BRAND STORY\\nWe’re pioneering through data\\nElastacloud have always been data pioneers: unleashing \\nthe power hidden within data through the design and \\nimplementation of world-class, enterprise-grade solutions. \\nWe are accelerators, empowering businesses to get where \\nthey’re going securely, cost-effectively, and faster – often \\ndeploying within days and weeks, not months or years.\\nOur founders, Richard Conway and Andy Cross were the \\nfirst pioneers; sharing an extraordinary talent for finding \\nthe hidden power and untapped opportunities in data and \\nthen unleashing its potential. If anyone said “it can’t be \\ndone”, they said “just watch us”, challenged the limits of \\nwhat ‘other experts’ claimed was possible and usually did \\nit faster than anyone else. \\nThrough advanced analytics, data science, best practice \\ndevelopment in AI and cloud data architectures – as well \\nas research and development of sustainable business \\npractice and green technologies – Elastacloud continue to \\npioneer through data to deliver accelerated transformation \\nand game-changing insights and outcomes, fast. \\nThe Elastacloud way\\nSince 2011, we have been building our commitment to \\ninnovation, intelligent solutions and accelerated outcomes \\ninto a global business with teams of over 300 data experts \\nacross the UK, Spain, Brazil and India. \\nWe generally refer to our team members as \\n‘Elastaclouders’. Our Elastaclouders consist of some of \\nthe finest data technologist talent around, and serve as \\nstrategic advisors to several of the world’s leading brands. \\nWe are highly respected and accomplished leaders in the \\ndata industry, with Richard and Andy recognised as present \\nMicrosoft Regional Directors and retired Microsoft Most \\nValuable Professionals.\\nJust like our founders have always done, we look at  \\nthings differently and are willing to push against \\nconvention to improve outcomes: pioneering through \\ndata to deliver more sustainable operations and elevate \\nour clients with a competitive advantage and commercial \\nedge. Whatever their objectives – from sustainability and growth to transformation – we push the boundaries \\nof possibility with a revolutionary approach and steely \\ndetermination to unshackle their data and harness the \\nopportunities it offers.\\nWe’re always searching for the beauty in data, operating \\nat a granular level and getting ‘up-close’ with it, so that \\nwe are able to identify and unlock the gateways that sit \\nin plain sight. We look at every challenge from multiple \\nperspectives, never losing sight of the bigger picture or of \\nboth micro and macro points of view. \\nWe love to solve big problems and give people the freedom \\nto experiment, learn quickly, and share ideas with others. \\nWe see ourselves as challengers and disruptors, even \\nmaverick at times. We are not afraid of the unconventional \\nand encourage our teams to take on big challenges \\nthat could fail, so we can learn and continue striving for \\nbreakthrough outcomes.\\nWe champion shared experience, innovation, collaboration, \\nimagination, creativity, adventure, and opportunity. This is \\nbecause we actively encourage our people to look for bold, \\nalternative, and creative solutions – not just in delivery of \\nour ground-breaking, data solutions for clients, but also \\nthrough our unconventional recognition of the importance \\nof play and imagination. \\nOne example of this is the way that Elastaclouders working \\nacross four countries are encouraged to participate \\nand compete in company-wide ‘Dungeons & Dragons’ \\ntournaments, run by our own in-house Dungeon Master. \\nSuch gameplay enhances ‘out-of-the-box’ thinking, problem \\nsolving and confidence building as well as strengthening \\nrelationships between teams.\\nIt’s all of this combined that gives us a unique ‘magic sauce’.\\nA culture of giving back\\nElastacloud firmly believes that data can break boundaries \\nand benefit humanity, which is why we are heavily \\ninvested in projects and actions that improve outcomes', metadata={'source': '../data/example/Elastacloud-Brand-Book.pdf', 'page': 5}),\n",
       " Document(page_content='A culture of giving back\\nElastacloud firmly believes that data can break boundaries \\nand benefit humanity, which is why we are heavily \\ninvested in projects and actions that improve outcomes \\nfor individuals and the planet. One way we do this is by \\nempowering our Elastaclouders to contribute to the wider \\ncommunity through sharing their digital skills.For well over a decade, Elastacloud has established and \\nmaintained various industry user groups: joining together \\nmore than 12,000 people around the world for community-\\nbased learning and innovation. This includes one of the \\nlargest data science communities in Europe.\\nWe are also proud to sponsor computer labs at Shanti \\nBhavan, a residential school in India for children born into \\nthe lowest socioeconomic class, which aims to uplift from \\npoverty through education and opportunity. Our team in \\nIndia run coding labs for the students there, sometimes \\nheld in the Elastacloud offices. \\nElastacloud has a deeply embedded commitment to \\ninclusivity, support, collaboration, nurturing and valuing \\nits people. Across the world, we actively encourage \\nElastaclouders to find a healthy balance of work and \\npersonal life: promoting time for self, family and friends, \\nfor leisure and wellbeing. In India for example, we  \\ndon’t allow our teams to consistently work outside of \\nstandard operating hours, despite this generally being  \\nthe expectation that people experience within Indian \\ncorporate culture.\\nWe take on graduates and experienced individuals from \\nall over (including from Shanti Bhavan) who possess the \\npassion and mindset to make a difference. ‘Elastaclouders’ \\nare encouraged to invest at least an hour of their own time \\neach month to mentor and support children, teaching them \\nhow to code and advance their IT literacy. This instils our \\ngraduates with a sense of community: ensuring that our \\nvalues are passed on to more people and helping to embed \\nsustainable social equity within the technologies we work in. \\nSince 2020, Elastacloud has been a foundation sponsor of \\nThe National Museum of Computing, which is based on the \\nfamous Bletchley Park estate where the Enigma code was \\ncracked, turning the tide of the war. We’re active in a wide \\nvariety of events and activities at this inspiring educational \\nvenue; one that carries so much historical value and \\nsignificance to our industry. \\nAlthough our Elastaclouders are widely spread \\ngeographically, we are united by a culture of pioneering for \\nthe greater good: harnessing data to break boundaries and \\nbenefit our people and our world.', metadata={'source': '../data/example/Elastacloud-Brand-Book.pdf', 'page': 5}),\n",
       " Document(page_content='OUR BRAND BOILERPLATES\\nBoilerplate - longer version (409 words)\\nElastacloud are data pioneers, unleashing the power hidden within data \\nthrough the design and implementation of world-class, enterprise-grade \\nsolutions. Through advanced analytics, data science, best practice \\ndevelopment in AI and cloud data architectures – as well as research and \\ndevelopment of sustainable business practice and green technologies – we \\npioneer through data to deliver accelerated transformational outcomes and \\ngame-changing insights, fast. We are accelerators, empowering businesses \\nto get where they’re going securely, cost-effectively, and more quickly – often \\ndeploying within weeks, not months or years.\\nOur core competencies are in design and delivery of enterprise data platform \\nand AI solutions:  \\n   Enterprise Data Platform delivery\\n   Azure Architecture\\n   Machine Learning Operations\\n   Digital Twins and IoT\\n   Sustainability Solutions and Reporting\\n   Intelligent Apps and Enterprise Search Development\\n   Web and BI Data Visualisation\\nThe Elastacloud team consists of some of the finest data technologists \\naround, and serve as strategic advisors to several of the world’s leading   \\nbrands. We are highly respected and accomplished leaders in the data \\nindustry: our co-founders are recognised as Microsoft Regional Directors, \\nalongside our team of Microsoft Most Valuable Professionals and Databricks \\nChampions.\\nAlthough our people are widely spread geographically, we are united by \\na culture of pioneering for the greater good: harnessing data to break \\nboundaries and benefit humanity and the planet. We love to solve big \\nproblems and give people the freedom to experiment, learn quickly, and share \\nideas with others. \\nWe see ourselves as challengers and disruptors, even maverick at times. \\nWe are not afraid of the unconventional and encourage our teams to take \\non big challenges that could fail, so we can learn and continue striving for \\nbreakthrough outcomes.\\nWe’re always searching for the beauty in data, operating at a granular level \\nand getting ‘up-close and personal’ with it, so that we are able to identify and \\nunlock the gateways that sit in plain sight. We look at every challenge from \\nmultiple perspectives, never losing sight of the bigger picture or of both micro \\nand macro points of view.\\nJust like our founders have always done, we look at things differently and are \\nwilling to push against convention to improve outcomes: pioneering through \\ndata to deliver more sustainable operations and elevate our clients with a \\ncompetitive advantage and commercial edge. Whatever their objectives – \\nfrom sustainability and growth to transformation – we push the boundaries \\nof possibility with a revolutionary approach and steely determination to \\nunshackle their data and harness the opportunities it offers.Boilerplate - short version (60 words)\\nElastacloud are data pioneers, designing and delivering world-class, \\nenterprise-grade solutions that unleash the power hidden within data. \\nUnited by a culture of pioneering for the greater good, we fuse data \\nscience, intelligence, and innovation, to enable businesses to accelerate \\ntransformation, achieve strategic outcomes, meet goals faster, and \\nbenefit from the game-changing insights that their data can provide.', metadata={'source': '../data/example/Elastacloud-Brand-Book.pdf', 'page': 6}),\n",
       " Document(page_content='OUR LOGO\\nOur logo shows two data squares dropping into, or emanating \\nfrom the E of our name. This is to represent how we unleash \\nthe power and opportunity hidden in plain sight within data, \\nto elevate businesses, accelerate transformation and deliver \\ngame-changing insights and outcomes. \\nOur logo is one of the ways that people will recognise us.  \\nIt is a valuable asset to our business and must not be \\naltered, re-shaped, redrawn or used in any other colours or \\napplications other than as shown within this brand book. \\nThere are three acceptable colour variants for our logo -  \\nno other variations can be used or created. \\nWhen placing the logo against a solid colour background,  \\nuse only the corresponding colour combinations shown here.\\nWhen placing the logo on top of a photograph, please use  \\nthe version that achieves the greatest legibility.', metadata={'source': '../data/example/Elastacloud-Brand-Book.pdf', 'page': 7}),\n",
       " Document(page_content='OUR ICON\\nOur E icon is a valuable asset to our business and must not \\nbe altered, re-shaped, redrawn or used in any other colours or \\napplications other than as shown within this brand book.  \\nThe E icon can be used as an avatar or profile image, or when \\nthere is not enough space to include the entire logo.\\nThere are three acceptable colour variants for our E icon -  \\nno other variations can be used or created. \\nWhen placing the E icon against a solid colour background, \\nuse only the corresponding colour combinations shown here.\\nWhen placing the E icon on top of a photograph, please use \\nthe version that achieves the greatest legibility.', metadata={'source': '../data/example/Elastacloud-Brand-Book.pdf', 'page': 8}),\n",
       " Document(page_content='OUR STRAPLINE\\nOur strapline is ‘Pioneering Through Data’ and this can be used as a logo lock-up as shown here.', metadata={'source': '../data/example/Elastacloud-Brand-Book.pdf', 'page': 9}),\n",
       " Document(page_content='RESPECTING OUR LOGO\\nWhen using the logo, there is a minimum amount of \\nclear space (the exclusion zone) that must always \\nbe left around the logo. Nothing else should ever \\nencroach within this space. This area is equivalent \\nto the E icon as illustrated on this page.\\nThe minimum sizes that the logo can be used are \\nset at 25mm for print applications and 100px for \\ndigital applications.\\nTo ensure the logo is always legible and accessible, \\nespecially with printed materials, our logo should \\nnever appear at sizes smaller than this.Minimum width: 25mm\\nMinimum width: 100px', metadata={'source': '../data/example/Elastacloud-Brand-Book.pdf', 'page': 10}),\n",
       " Document(page_content='KEEPING OUR LOGO TRUEDo not use the wrong colour variation\\nDo not change the opacity\\nDo not squeeze or stretchDo not add a drop shadow\\nDo not change the colours\\nDo not use on an angle\\nWe’re very proud of our logo and this brand book helps us \\nto ensure there is always consistency in the way it is used. \\nPlease only ever use the logo in the correct colours and fonts \\nas outlined within this document and never distort or change \\nany part of it. We must ensure that our logo always looks as \\ngood as we intended it to, across everything we do.\\nHere are some examples of how our logo must never be \\naltered or presented:', metadata={'source': '../data/example/Elastacloud-Brand-Book.pdf', 'page': 11}),\n",
       " Document(page_content='OUR SUB-BRAND (SOLUTIONS) LOGOS \\nData A nalytics \\nPlatform\\nData A nalytics \\nPlatform', metadata={'source': '../data/example/Elastacloud-Brand-Book.pdf', 'page': 12}),\n",
       " Document(page_content='OUR SUB-BRAND (SOLUTIONS) LOGOS \\nIntelligent \\nSpaces\\nIntelligent Spaces', metadata={'source': '../data/example/Elastacloud-Brand-Book.pdf', 'page': 13}),\n",
       " Document(page_content='OUR COLOUR PALETTE\\nElastacloud navy\\nC:87 M:75 Y:45 K:49\\nR:41 B:48 B:69\\n#293045Elastacloud blue\\nC:75 M:38 Y:0 K:0\\nR:45 B:130 B:219\\n#2D82DBElastacloud sky\\nC:33 M:2 Y:0 K:0\\nR:178 B:223 B:255\\n#B2DFFF\\nElastacloud yellow\\nC:20 M:0 Y:78 K:0\\nR:277 B:247 B:82\\n#E3F752Accent coloursCore brand colours\\nElastacloud green\\nC:56 M:0 Y:91 K:0\\nR:110 B:235 B:71\\n#6EEB47\\nThis is our approved colour palette. Please \\nensure that the right colour references are \\nused for each application e.g. CMYK for \\nprint, RGB for screen and Hex for web.', metadata={'source': '../data/example/Elastacloud-Brand-Book.pdf', 'page': 14}),\n",
       " Document(page_content='OUR TYPEFACES\\nSHORT HEA DLINES\\nTERMINA - DEMI, UPPERCASE\\nLong headlines and subtitl es\\nRoboto - Bold, Sentence case\\nRoboto - Light, Sentence case\\nBody C opy\\nRoboto - Regular, Sentence case\\nTermina font can be activated through  \\nAdobe Typekit at fonts.adobe.com/fonts/termin a\\nRoboto can be downloaded for free from Google Fonts \\nat fonts.google.com/specimen/Roboto', metadata={'source': '../data/example/Elastacloud-Brand-Book.pdf', 'page': 15}),\n",
       " Document(page_content='OUR BRAND TOOL KIT\\nBRAND ASSETS\\nIn addition to our logos, colour palette and fonts, there are other assets in our brand tool kit \\nthat help to make our communications distinctively Elastacloud. These include:\\n   Data square graphics\\n   Data bridge graphics\\n   Images\\n   A combination of all of the above\\nThe following pages provide more insight about how these should be used.\\nDATA SQUARES\\nCan be made up of any of the colours in the approved \\nbrand palette. Can be single squares or adjacent squares \\ntouching on the corner points only, but never placed \\nside by side. Squares can be used effectively as design \\nfeatures, as shown in ‘Five core messages’ above.DATA BRIDGE\\nA blend of colours from the approved \\npalette. Instructions for how to replicate \\nthis effect are available.', metadata={'source': '../data/example/Elastacloud-Brand-Book.pdf', 'page': 16}),\n",
       " Document(page_content='OUR VISUAL LANGUAGE\\nElastacloud unleashes the power and opportunity hidden within data, through the \\ndesign and implementation of world-class, enterprise-grade solutions. We use and \\nconnect data to build a better world and we’re always searching for the beauty in data. \\nWe operate at a granular level by getting ‘up-close’ with data, so that we can identify \\nand unlock the opportunities that lay hidden in plain sight. We look at every challenge \\nfrom multiple perspectives, never losing a sense of the bigger picture or of both micro \\nand macro points of view. We always apply the Elastacloud ‘magic sauce’ to deliver \\naccelerated outcomes.\\nThese sentiments should, wherever possible and appropriate, be represented through \\nthe unique styling of the visuals, brand assets and ‘hero’ imagery that we use in external \\n(and internal) communications and brand touch points (such as our website or sales \\nand marketing material). The way we present our visual imagery is by implementing a \\ncombination of three key components :\\n1. Use of solid brand colour ‘ data squares ’ to represent how Elastacloud intersects with \\nand benefits our world (whilst directly echoing the two data squares that drop into \\nthe E of our logo).\\n2. Use of a distinctive brand asset that we refer to as a ‘ data bridge ’. This ‘rainbow-\\nlike’ coloured line (comprising a blend of the Elastacloud colour palette) is a visual representation of data flowing between points and intersecting with smaller ‘ data \\nsquares ’, overlaid on top of our hero images. \\n3. Use of exciting, intriguing, engaging, and stunningly detailed hero images  of i) \\nclose-up nature shots  and/or of ii) clients, people and industry . These images \\nare interchangeable depending upon the context they are being presented in and \\nwhat they are being used for, e.g. on a case study, sales deck or LinkedIn advert. \\nHero images can be either: \\ni) Close up images of nature  to represent how Elastacloud gets up-close with \\ndata and operates at a granular level, to gain the understanding required to \\nprovide effective, fast solutions. We use super close-up natural images (flora and \\nfauna: animals, birds, plants, food etc.), to reveal the hidden detail, colour, texture, \\npattern and beauty (as well as repetition and connection) that becomes apparent \\nwhen magnified. This is a metaphor for how we work with data and is also a \\nreflection of our sustainability focus.\\nand/or\\nii) Macro images to reflect our client, people and industry  expertise and \\nexperience, in order to show real-world applications of what we do and the \\nimpact we have on people and the planet.', metadata={'source': '../data/example/Elastacloud-Brand-Book.pdf', 'page': 17}),\n",
       " Document(page_content='USE OF PHOTOGRAPHY\\nHere are some example nature and people/industry images incorporating the ‘ data squares ’ and ‘ data bridge ’ assets. \\nA full gallery of images has been created and is available to be used in presentations and on the web.\\nWhich images should be used and where, is purely at the discretion of the designer or producer of the item. In real \\nworld applications or case studies, relevant images of people and industry may be most appropriate. When concepts \\nare broader or more abstract, then nature images may work best. Images are interchangeable but consistently linked \\nin visual language by the integration of the ‘ data squares ’ and ‘ data bridge ’ assets.', metadata={'source': '../data/example/Elastacloud-Brand-Book.pdf', 'page': 18}),\n",
       " Document(page_content='EXAMPLES OF APPLICATION', metadata={'source': '../data/example/Elastacloud-Brand-Book.pdf', 'page': 19}),\n",
       " Document(page_content='EXAMPLES OF APPLICATION', metadata={'source': '../data/example/Elastacloud-Brand-Book.pdf', 'page': 20}),\n",
       " Document(page_content='GLOSSARY OF TERMS\\nAccelerators  – in relation to outcomes, at Elastacloud \\nwe’re known to ‘accelerate’ processes to scale for \\ncustomers with our expertise. \\nAdvanced analytics  – Goes beyond historical reporting \\nand data aggregation of traditional BI, mathematical, \\nprobabilistic, and statistical modelling techniques to \\nenable predictive processing and automated decision-\\nmaking.\\nAI – Artificial Intelligence is a field that combines data \\nscience and robust datasets that enable problem-solving. \\n(refer here for types of AI) \\nAWS  – Amazon Web Services\\nAzure Architecture  – process of creating, deploying, \\noperating and managing cloud-based application.\\nData bridge  – An Elastacloud-coined term used as a way \\nof naming the ‘rainbow-like’ graphic device used in some of \\nour visual imagery and branding.\\nData insights  – Deep understanding/knowledge on the \\nvalue gain and what it means for an organisation from \\nanalysing sets of information (analytics). \\nData lake  – Data which is cleaned, enriched, and \\ntransformed so it can act as the ‘single source of truth’ that \\nusers can trust. \\nData pioneer  – Our founders are pioneers in data: \\nauthoring a data science degree on academy.microsoft.\\ncom, co-founding the UK Azure User Group, and a key \\ncontributor to Apache open source projects, with countless \\npublic contributions to Azure from our wider team. Data science  – Combines statistics (and maths), \\nprogramming, advanced analytics, artificial intelligence \\n(AI), and machine learning to uncover actionable insights \\nhidden in an organisations/customers data.  \\nData squares  – An Elastacloud-coined term used as a way \\nof naming the solid colour graphic squares that appear in \\nour logo and in our visual imagery / branding.\\nDigital twins – a virtual model designed to accurately \\nreflect a physical object. (Not to be confused with Azure \\nDigital Twins [PaaS]).\\nElastaclouders – An Elastacloud-coined term used as an \\naffectionate and unique way of referring to Elastacloud \\nemployees and team members across the world.\\nEnterprise data platform  – Central data repository of an \\norganisation where all intelligence data is unified.\\nEnterprise search development – refer to ‘Knowledge \\nMiner’\\nESG ¬– An investment risk management framework \\nand tool to encourage more responsible investing. It is \\nimportant that Environmental, Social and Governance \\nfactors are considered when making investment decisions. \\nFaster – We help businesses to achieve their goals faster \\nthan a business would normally by delivering actionable \\ninsights and more efficient processes and services. \\nIoT: ‘Internet of Things’  - Physical hardware that is \\nembedded with sensors that allow the exchange of data \\nwith other devices and systems over the internet. (Azure \\nIoT – refers to the above but managed by platforms such as Azure IoT Hub and Azure Digital Twins to construct a \\nsolution.)  \\nKnowledge Miner – also known as ‘Intelligent Search’ is \\npropitiatory search tool power by Azure Cognitive Services \\nthat allows advanced search capabilities across an \\norganisation’s dataset. \\nMachine learning  – A process that a computer follows to \\nachieve artificial intelligence. It uses algorithms to identify \\npatterns within data and those patterns are then used to \\ncreate a data model that can make predictions.\\n‘More quickly’ – See ‘Faster’\\nPower BI – Interactive data visualisation software. \\nSQL (also known as Sequel) = Structured Query Language \\n– standardised programming language that’s used to \\nmanage relational databases and perform operations on \\nthe data in them.\\nSustainability – Shorthand for Sustainable Development, \\ndefined in the 1987 publication of the UN’s Brundtland \\nCommission’s ‘Our Common Future’ as a value-system \\nbased on personal and organisational values needed to \\n“meet the needs of the present without compromising the \\nability of future generations to meet their own needs”. \\nUnleash / Unshackled  – Elastacloud language used to', metadata={'source': '../data/example/Elastacloud-Brand-Book.pdf', 'page': 21}),\n",
       " Document(page_content='“meet the needs of the present without compromising the \\nability of future generations to meet their own needs”. \\nUnleash / Unshackled  – Elastacloud language used to \\nreflect how Elastacloud identifies, unlocks, releases, \\nharnesses and utilises the potential opportunity and power \\nthat lies hidden within the data it works with, to great effect \\nand in order to deliver accelerated outcomes.HERE’S A GUIDE TO SOME OF THE THINGS WE TEND TO TALK ABOUT AND PHRASES WE USE \\nWITHIN AND BEYOND THIS DOCUMENT . IN SOME CASES, THIS INCLUDES PROOF POINTS \\nAND ‘REASONS TO BELIEVE’ IN ORDER TO VALIDATE STATEMENTS AND CLAIMS MADE:', metadata={'source': '../data/example/Elastacloud-Brand-Book.pdf', 'page': 21}),\n",
       " Document(page_content='THANK YOU FOR ADHERING TO THESE GUIDELINES\\nFor futher questions and styling advice, please \\ncontact Emma Benjamin at Creative Clinic:\\nemma.benjmain@thecreativeclinic.com\\ndesigned by thecreativeclinic.com', metadata={'source': '../data/example/Elastacloud-Brand-Book.pdf', 'page': 22})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.schema.document.Document"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document import Document\n",
    "\n",
    "doc = Document(page_content=\"foo\")\n",
    "\n",
    "doc_with_metadata = Document(page_content=\"foo\", metadata={\"source\": \"1\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AntonioVelasco\\.virtualenvs\\llm_utilities-HQ1bCkrd\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import create_qa_with_sources_chain\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "\n",
    "# create the open-source embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# load it into Chroma\n",
    "db = Chroma.from_documents(pages, embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import create_qa_with_sources_chain, RetrievalQA\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "\n",
    "# create the open-source embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# load it into Chroma\n",
    "db = Chroma.from_documents(pages, embedding_function)\n",
    "\n",
    "\n",
    "llm_src = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\")\n",
    "\n",
    "qa_chain = create_qa_with_sources_chain(llm_src)\n",
    "\n",
    "doc_prompt = PromptTemplate(\n",
    "    template=\"Content: {page_content}\\n Source: {page}\", # look at the prompt does have page#\n",
    "    input_variables=[\"page_content\", \"source\"],\n",
    ")\n",
    "\n",
    "final_qa_chain = StuffDocumentsChain(\n",
    "    llm_chain=qa_chain, \n",
    "    document_variable_name='context',\n",
    "    document_prompt=doc_prompt,\n",
    ")\n",
    "retrieval_qa = RetrievalQA(\n",
    "    retriever=db.as_retriever(),\n",
    "    combine_documents_chain=final_qa_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer\": \"Elastacloud's mission is to help businesses achieve their goals faster by delivering actionable insights and more efficient processes and services.\",\n",
      "  \"sources\": [\"21\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"What is EC Mission?\"\n",
    "\n",
    "answer_1 = retrieval_qa.run(query)\n",
    "print(answer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Elastacloud's mission is to be data pioneers, unleashing the power of data, accelerating transformational outcomes, serving as trusted advisors, and fostering a global community of innovation and collaboration.\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(answer_1)[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Results\": {\"mission\": \"<>\", \"Colour\": \"<Elastacloud marketing palette>\"}}'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "field_names = [\"mission\", \"Colour\"]\n",
    "field_descriptions = [\"<>\", \"<Elastacloud marketing palette>\"]\n",
    "\n",
    "json_template = json.dumps({\"Results\": dict(zip(field_names, field_descriptions))})\n",
    "json_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Results\": [{\"mission\": \"<>\", \"Colour\": \"<Elastacloud marketing palette>\", \"Source page\": \"<Pages of the document containing the fields in int format>\"}]}\n"
     ]
    }
   ],
   "source": [
    "json_template = json.dumps(\n",
    "    {\n",
    "        \"Results\": [\n",
    "            dict(list(zip(field_names, field_descriptions)) + [(\"Source page\", \"<Page number>\")])\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(json_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Results\": [{\"mission\": \"<Extracted answer>\"}]}\n",
      "{\"Results\": [{\"Colour\": \"<Extracted answer>\"}]}\n"
     ]
    }
   ],
   "source": [
    "b=\"\"\n",
    "system = f\"\"\"\n",
    "You are an assistant tasked with extracting data from documents.\n",
    "Given a text extracted using OCR from a document, you will extract a user provided data field.\n",
    "Be thorough and extract all the information available.\n",
    "Write your output as a JSON with the format {b}.\n",
    "If you can't find the asked information, set it null.\n",
    "If there is any additional information of feedback from the infromation extraction, add a {{\"notes\": \"<additional-information>\"}}\n",
    "\"\"\"   # noqa E501\n",
    "\n",
    "for a in json_template:\n",
    "    b = json.dumps({\"Results\": [dict(zip([a], [\"<Extracted answer>\"]))]})\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = relevant_text\n",
    "\n",
    "json_template = json.dumps({ \n",
    "    \"Test Type\": \"<FIT or LOT>\",\n",
    "    \"Casing Shoe\": \"<Casing shoe size>\",\n",
    "    \"TVD (m)\": \"TVD in meters\",\n",
    "    \"Surface pressure (psi)\": \"<MW value in sg>\",\n",
    "    \"MW (sg)\": \"<MW value in sg>\",\n",
    "    \"EMW (sg)\": \"<EMW value in sg. Calculated as: EMW = MW + (P-FIT / (TVD-shoe * 1.421))>\"\n",
    "})\n",
    "\n",
    "system = f\"\"\"\n",
    "You are an API that given a text extracted using OCR from an End of Well Report will extract Formation Integrity Test (FIT) and Leak Off Test (LOT) results.\n",
    "Your response will be a JSON with as many entries as needed in the format {json_template}\n",
    "If there is a field that you can not find, set it a null.\n",
    "If the document has any kind of errors or is corrupted, add a field {{\"errors\": \"<error description>\"}}\n",
    "If there is any additional information of feedback from the infromation extraction, add a {{\"notes\": \"<additional-information>\"}}\n",
    "\n",
    "The format of your input will be the text of the relevant page.\n",
    "\"\"\"\n",
    "\n",
    "config = {\n",
    "    \"temperature\": 0.2,\n",
    "    \"max_tokens\": 512,\n",
    "    \"top_p\": 1,\n",
    "}\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": system},\n",
    "      {\"role\": \"user\", \"content\": input},\n",
    "    ],\n",
    "    temperature=config[\"temperature\"],\n",
    "    max_tokens=config[\"max_tokens\"],\n",
    "    top_p=config[\"top_p\"],\n",
    "  )\n",
    "\n",
    "print(response.get(\"choices\")[0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"text\": \"Formation Integrity Test (FIT)\\n\\nCasing Shoe: 10000 ft\\nTVD (m): 3000\\nSurface pressure (psi): 5000\\nMW (sg): 1.2\\n\\nLeak Off Test (LOT)\\n\\nCasing Shoe: 10000 ft\\nTVD (m): 3000\\nSurface pressure (psi): 5000\\nMW (sg): 1.2\\nEMW (sg): 1.3\"}\n"
     ]
    }
   ],
   "source": [
    "input = relevant_text\n",
    "\n",
    "json_template = json.dumps({ \n",
    "    \"Test Type\": \"<FIT or LOT>\",\n",
    "    \"Casing Shoe\": \"<Casing shoe size>\",\n",
    "    \"TVD (m)\": \"TVD in meters\",\n",
    "    \"Surface pressure (psi)\": \"<MW value in sg>\",\n",
    "    \"MW (sg)\": \"<MW value in sg>\",\n",
    "    \"EMW (sg)\": \"<EMW value in sg. Calculated as: EMW = MW + (P-FIT / (TVD-shoe * 1.421))>\"\n",
    "})\n",
    "\n",
    "system = f\"\"\"\n",
    "You are an API that given a text extracted using OCR from an End of Well Report will extract Formation Integrity Test (FIT) and Leak Off Test (LOT) results.\n",
    "Your response will be a JSON with as many entries as needed in the format {json_template}\n",
    "If there is a field that you can not find, set it a null.\n",
    "If the document has any kind of errors or is corrupted, add a field {{\"errors\": \"<error description>\"}}\n",
    "If there is any additional information of feedback from the infromation extraction, add a {{\"notes\": \"<additional-information>\"}}\n",
    "\n",
    "The format of your input will be the text of the relevant page.\n",
    "\"\"\"\n",
    "\n",
    "config = {\n",
    "    \"temperature\": 0.2,\n",
    "    \"max_tokens\": 512,\n",
    "    \"top_p\": 1,\n",
    "}\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-16k\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": system},\n",
    "      {\"role\": \"user\", \"content\": input},\n",
    "    ],\n",
    "    temperature=config[\"temperature\"],\n",
    "    max_tokens=config[\"max_tokens\"],\n",
    "    top_p=config[\"top_p\"],\n",
    "  )\n",
    "\n",
    "print(response.get(\"choices\")[0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good enough with 16k, let's check with form recogniser and see "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(encoder.encode(extracted_text[\"content\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = extracted_text[\"content\"]\n",
    "\n",
    "json_template = json.dumps({ \n",
    "    \"Test Type\": \"<FIT or LOT>\",\n",
    "    \"Casing Shoe\": \"<Casing shoe size>\",\n",
    "    \"TVD (m)\": \"TVD in meters\",\n",
    "    \"Surface pressure (psi)\": \"<MW value in sg>\",\n",
    "    \"EMW (sg)\": \"<EMW value in sg>\"\n",
    "})\n",
    "\n",
    "system = f\"\"\"\n",
    "You are an API that given a text extracted using OCR from an End of Well Report will extract Formation Integrity Test (FIT) and Leak Off Test (LOT) results.\n",
    "There can be multiple tests per shoe size and depth, please report them all.\n",
    "Your response will be a JSON with one entry per test in the format {json_template}.\n",
    "If there is a field that you can not find, set it a null.\n",
    "If the document has any kind of errors or is corrupted, add a field {{\"errors\": \"<error description>\"}}\n",
    "If there is any additional information of feedback from the infromation extraction, add a {{\"notes\": \"<additional-information>\"}}\n",
    "\n",
    "The format of your input will be the text of the relevant page.\n",
    "\"\"\"\n",
    "\n",
    "config = {\n",
    "    \"temperature\": 0.2,\n",
    "    \"max_tokens\": 512,\n",
    "    \"top_p\": 1,\n",
    "}\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-16k\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": system},\n",
    "      {\"role\": \"user\", \"content\": input},\n",
    "    ],\n",
    "    temperature=config[\"temperature\"],\n",
    "    max_tokens=config[\"max_tokens\"],\n",
    "    top_p=config[\"top_p\"],\n",
    "  )\n",
    "\n",
    "print(response.get(\"choices\")[0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Llama Index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"../llama_dir/\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The EMW of the FIT performed on the well 206/12a-3 is 1.75sg.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"what's the EMW of the FIT performed on the well 206/12a-3?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two tests were performed on the well 206/12a-3.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"How many test where performend on the well 206/12a-3?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LOT and FIT are reported on page 53 of the end of well 206/12a-3 report.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"In which page on the end of well 206/12a-3 report are the LOT and FIT reported?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLama Index Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[path]\n",
    ").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"In which page are the LOT and FIT reported?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_template = json.dumps({\n",
    "    \"Test Type\": \"<FIT or LOT>\",\n",
    "    \"Casing Shoe\": \"<Casing shoe size>\",\n",
    "    \"TVD (m)\": \"TVD in meters\",\n",
    "    \"Surface pressure (psi)\": \"<Surface pressure value>\",\n",
    "    \"MW (sg)\": \"<MW value in sg>\",\n",
    "    \"EMW (sg)\": \"<EMW value in sg>\"\n",
    "})\n",
    "\n",
    "system = f\"\"\"\n",
    "You are an assistant that given a text extracted using OCR from an End of Well Report will extract 'Formation Integrity Test' (FIT) and 'Leak Off Test' (LOT) results.\n",
    "There can be multiple tests, report all of them.\n",
    "Write your output as a list with an entry with the format {json_template} per each test you find, separated by commas.\n",
    "If there is a field that you can not find, set it a null.\n",
    "If the document has any kind of errors or is corrupted, add a field {{\"errors\": \"<error description>\"}}\n",
    "If there is any additional information of feedback from the infromation extraction, add a {{\"notes\": \"<additional-information>\"}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Test Type\": \"FIT\", \"Casing Shoe\": \"20\", \"TVD (m)\": \"536\", \"Surface pressure (psi)\": \"101.0\", \"MW (sg)\": \"1.15\", \"EMW (sg)\": \"1.26\"},\n",
      "{\"Test Type\": \"LOT\", \"Casing Shoe\": \"20\", \"TVD (m)\": \"536\", \"Surface pressure (psi)\": \"84.0\", \"MW (sg)\": \"1.15\", \"EMW (sg)\": \"1.26\"},\n",
      "{\"Test Type\": \"FIT\", \"Casing Shoe\": \"13 3/8\", \"TVD (m)\": null, \"Surface pressure (psi)\": \"328\", \"MW (sg)\": \"1.55\", \"EMW (sg)\": null},\n",
      "{\"Test Type\": \"LOT\", \"Casing Shoe\": \"13 3/8\", \"TVD (m)\": null, \"Surface pressure (psi)\": \"360\", \"MW (sg)\": \"1.55\", \"EMW (sg)\": null}\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(system)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data from Form Recogniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "# OCR from base form recogniser\n",
    "def base_form_recogniser(pdf_bytes: io.BytesIO) -> dict:\n",
    "    document = pdf_bytes.getvalue()\n",
    "\n",
    "    # Start the document analysis\n",
    "    poller = document_analysis_client.begin_analyze_document(\"prebuilt-document\", document, polling_interval=5)\n",
    "\n",
    "    # Get the result\n",
    "    result = poller.result()\n",
    "    data = result.to_dict()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n",
      "8\n",
      "13\n",
      "15\n",
      "52\n",
      "53\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "from PyPDF4 import PdfFileWriter, PdfFileReader\n",
    "\n",
    "inputpdf = PdfFileReader(open(path, \"rb\"))\n",
    "\n",
    "output = PdfFileWriter()\n",
    "\n",
    "relevant_text = \"\"\n",
    "\n",
    "with pdfplumber.open(path) as pdf:\n",
    "    for page in pdf.pages:\n",
    "        if page.search(\"FIT\") and page.search(\"LOT\"):\n",
    "            output.addPage(inputpdf.pages[page.page_number])\n",
    "            print(page.page_number)\n",
    "\n",
    "output_bytesio = io.BytesIO()\n",
    "\n",
    "output.write(output_bytesio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text = base_form_recogniser(output_bytesio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader, VectorStoreIndex, ServiceContext\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index import Document\n",
    "\n",
    "text_list = [extracted_text[\"content\"]]\n",
    "documents = [Document(text=t) for t in text_list]\n",
    "\n",
    "node_parser = SimpleNodeParser.from_defaults(chunk_size=4096, chunk_overlap=200)\n",
    "service_context = ServiceContext.from_defaults(node_parser=node_parser)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_template = json.dumps({\n",
    "    \"Test Type\": \"<FIT or LOT>\",\n",
    "    \"Casing Shoe\": \"<Casing shoe size>\",\n",
    "    \"TVD (m)\": \"TVD in meters\",\n",
    "    \"Surface pressure (psi)\": \"<Surface pressure value>\",\n",
    "    \"MW (sg)\": \"<MW value in sg>\",\n",
    "    \"EMW (sg)\": \"<EMW value in sg>\"\n",
    "})\n",
    "\n",
    "system = f\"\"\"\n",
    "You are an assistant that given a text extracted using OCR from an End of Well Report will extract 'Formation Integrity Test' (FIT) and 'Leak Off Test' (LOT) results.\n",
    "You must prioritize reporting the EMW value, meassured in sg.\n",
    "There can be multiple tests, report all of them.\n",
    "Write an entry with the format {json_template} per each test you find.\n",
    "If there is a field that you can not find, set it a null.\n",
    "If the document has any kind of errors or is corrupted, add a field {{\"errors\": \"<error description>\"}}\n",
    "If there is any additional information of feedback from the infromation extraction, add a {{\"notes\": \"<additional-information>\"}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Test Type\": \"FIT\", \"Casing Shoe\": \"9 5/8\", \"TVD (m)\": \"2081.4\", \"Surface pressure (psi)\": \"null\", \"MW (sg)\": \"null\", \"EMW (sg)\": \"1.69\"}\n",
      "{\"Test Type\": \"LOT\", \"Casing Shoe\": \"null\", \"TVD (m)\": \"536\", \"Surface pressure (psi)\": \"84.0\", \"MW (sg)\": \"null\", \"EMW (sg)\": \"1.26\"}\n",
      "{\"Test Type\": \"LOT\", \"Casing Shoe\": \"null\", \"TVD (m)\": \"null\", \"Surface pressure (psi)\": \"null\", \"MW (sg)\": \"null\", \"EMW (sg)\": \"null\"}\n",
      "{\"Test Type\": \"FIT\", \"Casing Shoe\": \"13 3/8\", \"TVD (m)\": \"null\", \"Surface pressure (psi)\": \"null\", \"MW (sg)\": \"null\", \"EMW (sg)\": \"1.55\"}\n",
      "{\"Test Type\": \"FIT\", \"Casing Shoe\": \"null\", \"TVD (m)\": \"null\", \"Surface pressure (psi)\": \"null\", \"MW (sg)\": \"null\", \"EMW (sg)\": \"null\"}\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(system)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
